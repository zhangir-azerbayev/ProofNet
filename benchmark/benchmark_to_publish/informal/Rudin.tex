\documentclass{article}

\title{\textbf{
Exercises from \\
\textit{Principles of Mathematical Analysis} \\
by Walter Rudin
}}

\date{}

\usepackage{amsmath, amsthm}
\usepackage{amssymb}


\theoremstyle{definition}
\newtheorem{lem}{Lemma}[section]
\newtheorem{cor}[lem]{Corollary}
\newtheorem{prop}[lem]{Proposition}
\newtheorem{thm}[lem]{Theorem}
\newtheorem{remark}[lem]{Remark}
\newtheorem{defn}[lem]{Definition}

\newtheorem*{prop*}{Proposition}
\newtheorem*{thm*}{Theorem}
\newtheorem*{defn*}{Definition}
\newtheorem*{lem*}{Lemma}

\begin{document}
\maketitle


\paragraph{Exercise 1.1a} If $r$ is rational $(r \neq 0)$ and $x$ is irrational, prove that $r+x$ is irrational.
\begin{proof}
    If $r$ and $r+x$ were both rational, then $x=r+x-r$ would also be rational.
\end{proof}



\paragraph{Exercise 1.1b} If $r$ is rational $(r \neq 0)$ and $x$ is irrational, prove that $rx$ is irrational.
\begin{proof}
    If $r x$ were rational, then $x=\frac{r x}{r}$ would also be rational.
\end{proof}



\paragraph{Exercise 1.2} Prove that there is no rational number whose square is $12$.
\begin{proof}
    Suppose $m^2=12 n^2$, where $m$ and $n$ have no common factor. It follows that $m$ must be even, and therefore $n$ must be odd. Let $m=2 r$. Then we have $r^2=3 n^2$, so that $r$ is also odd. Let $r=2 s+1$ and $n=2 t+1$. Then
$$
4 s^2+4 s+1=3\left(4 t^2+4 t+1\right)=12 t^2+12 t+3,
$$
so that
$$
4\left(s^2+s-3 t^2-3 t\right)=2 .
$$
But this is absurd, since 2 cannot be a multiple of 4 .
\end{proof}



\paragraph{Exercise 1.4} Let $E$ be a nonempty subset of an ordered set; suppose $\alpha$ is a lower bound of $E$ and $\beta$ is an upper bound of $E$. Prove that $\alpha \leq \beta$.
\begin{proof}
Since $E$ is nonempty, there exists $x \in E$. Then by definition of lower and upper bounds we have $\alpha \leq x \leq \beta$, and hence by property $i i$ in the definition of an ordering, we have $\alpha<\beta$ unless $\alpha=x=\beta$.
\end{proof}



\paragraph{Exercise 1.5} Let $A$ be a nonempty set of real numbers which is bounded below. Let $-A$ be the set of all numbers $-x$, where $x \in A$. Prove that $\inf A=-\sup (-A)$.
\begin{proof}
    We need to prove that $-\sup (-A)$ is the greatest lower bound of $A$. For brevity, let $\alpha=-\sup (-A)$. We need to show that $\alpha \leq x$ for all $x \in A$ and $\alpha \geq \beta$ if $\beta$ is any lower bound of $A$.

Suppose $x \in A$. Then, $-x \in-A$, and, hence $-x \leq \sup (-A)$. It follows that $x \geq-\sup (-A)$, i.e., $\alpha \leq x$. Thus $\alpha$ is a lower bound of $A$.

Now let $\beta$ be any lower bound of $A$. This means $\beta \leq x$ for all $x$ in $A$. Hence $-x \leq-\beta$ for all $x \in A$, which says $y \leq-\beta$ for all $y \in-A$. This means $-\beta$ is an upper bound of $-A$. Hence $-\beta \geq \sup (-A)$ by definition of sup, i.e., $\beta \leq-\sup (-A)$, and so $-\sup (-A)$ is the greatest lower bound of $A$.
\end{proof}



\paragraph{Exercise 1.8} Prove that no order can be defined in the complex field that turns it into an ordered field.
\begin{proof}
    By Part (a) of Proposition $1.18$, either $i$ or $-i$ must be positive. Hence $-1=i^2=(-i)^2$ must be positive. But then $1=(-1)^2$, must also be positive, and this contradicts Part $(a)$ of Proposition 1.18, since 1 and $-1$ cannot both be positive.
\end{proof}



\paragraph{Exercise 1.11a} If $z$ is a complex number, prove that there exists an $r\geq 0$ and a complex number $w$ with $| w | = 1$ such that $z = rw$.
\begin{proof}
    If $z=0$, we take $r=0, w=1$. (In this case $w$ is not unique.) Otherwise we take $r=|z|$ and $w=z /|z|$, and these choices are unique, since if $z=r w$, we must have $r=r|w|=|r w|=|z|, z / r$
\end{proof}



\paragraph{Exercise 1.12} If $z_1, \ldots, z_n$ are complex, prove that $|z_1 + z_2 + \ldots + z_n| \leq |z_1| + |z_2| + \cdots + |z_n|$.
\begin{proof}
    We can apply the case $n=2$ and induction on $n$ to get
$$
\begin{aligned}
\left|z_1+z_2+\cdots z_n\right| &=\left|\left(z_1+z_2+\cdots+z_{n-1}\right)+z_n\right| \\
& \leq\left|z_1+z_2+\cdots+z_{n-1}\right|+\left|z_n\right| \\
& \leq\left|z_1\right|+\left|z_2\right|+\cdots+\left|z_{n-1}\right|+\left|z_n\right|
\end{aligned}
$$
\end{proof}



\paragraph{Exercise 1.13} If $x, y$ are complex, prove that $||x|-|y|| \leq |x-y|$.
\begin{proof}
    Since $x=x-y+y$, the triangle inequality gives
$$
|x| \leq|x-y|+|y|
$$
so that $|x|-|y| \leq|x-y|$. Similarly $|y|-|x| \leq|x-y|$. Since $|x|-|y|$ is a real number we have either ||$x|-| y||=|x|-|y|$ or ||$x|-| y||=|y|-|x|$. In either case, we have shown that ||$x|-| y|| \leq|x-y|$.
\end{proof}



\paragraph{Exercise 1.14} If $z$ is a complex number such that $|z|=1$, that is, such that $z \bar{z}=1$, compute $|1+z|^{2}+|1-z|^{2}$.
\begin{proof}
    $|1+z|^2=(1+z)(1+\bar{z})=1+\bar{z}+z+z \bar{z}=2+z+\bar{z}$. Similarly $|1-z|^2=(1-z)(1-\bar{z})=1-z-\bar{z}+z \bar{z}=2-z-\bar{z}$. Hence
$$
|1+z|^2+|1-z|^2=4 \text {. }
$$
\end{proof}



\paragraph{Exercise 1.16a} Suppose $k \geq 3, x, y \in \mathbb{R}^k, |x - y| = d > 0$, and $r > 0$. Prove that if $2r > d$, there are infinitely many $z \in \mathbb{R}^k$ such that $|z-x|=|z-y|=r$.
\begin{proof}
    (a) Let w be any vector satisfying the following two equations:
$$
\begin{aligned}
\mathbf{w} \cdot(\mathbf{x}-\mathbf{y}) &=0, \\
|\mathbf{w}|^2 &=r^2-\frac{d^2}{4} .
\end{aligned}
$$
From linear algebra it is known that all but one of the components of a solution $\mathbf{w}$ of the first equation can be arbitrary. The remaining component is then uniquely determined. Also, if $w$ is any non-zero solution of the first equation, there is a unique positive number $t$ such that $t$ w satisfies both equations. (For example, if $x_1 \neq y_1$, the first equation is satisfied whenever
$$
z_1=\frac{z_2\left(x_2-y_2\right)+\cdots+z_k\left(x_k-y_k\right)}{y_1-x_1} .
$$
If $\left(z_1, z_2, \ldots, z_k\right)$ satisfies this equation, so does $\left(t z_1, t z_2, \ldots, t z_k\right)$ for any real number $t$.) Since at least two of these components can vary independently, we can find a solution with these components having any prescribed ratio. This ratio does not change when we multiply by the positive number $t$ to obtain a solution of both equations. Since there are infinitely many ratios, there are infinitely many distinct solutions. For each such solution $\mathbf{w}$ the vector $\mathbf{z}=$ $\frac{1}{2} \mathrm{x}+\frac{1}{2} \mathrm{y}+\mathrm{w}$ is a solution of the required equation. For
$$
\begin{aligned}
|\mathrm{z}-\mathbf{x}|^2 &=\left|\frac{\mathbf{y}-\mathbf{x}}{2}+\mathbf{w}\right|^2 \\
&=\left|\frac{\mathbf{y}-\mathbf{x}}{2}\right|^2+2 \mathbf{w} \cdot \frac{\mathbf{x}-\mathbf{y}}{2}+|\mathbf{w}|^2 \\
&=\frac{d^2}{4}+0+r^2-\frac{d^2}{4} \\
&=r^2
\end{aligned}
$$
and a similar relation holds for $|z-y|^2$.
\end{proof}



\paragraph{Exercise 1.17} Prove that $|\mathbf{x}+\mathbf{y}|^{2}+|\mathbf{x}-\mathbf{y}|^{2}=2|\mathbf{x}|^{2}+2|\mathbf{y}|^{2}$ if $\mathbf{x} \in R^{k}$ and $\mathbf{y} \in R^{k}$.
\begin{proof}
    The proof is a routine computation, using the relation
$$
|x \pm y|^2=(x \pm y) \cdot(x \pm y)=|x|^2 \pm 2 x \cdot y+|y|^2 .
$$
If $\mathrm{x}$ and $\mathrm{y}$ are the sides of a parallelogram, then $\mathrm{x}+\mathrm{y}$ and $\mathbf{x}-\mathrm{y}$ are its diagonals. Hence this result says that the sum of the squares on the diagonals of a parallelogram equals the sum of the squares on the sides.
\end{proof}



\paragraph{Exercise 1.18a} If $k \geq 2$ and $\mathbf{x} \in R^{k}$, prove that there exists $\mathbf{y} \in R^{k}$ such that $\mathbf{y} \neq 0$ but $\mathbf{x} \cdot \mathbf{y}=0$
\begin{proof}
    If $\mathbf{x}$ has any components equal to 0 , then $\mathbf{y}$ can be taken to have the corresponding components equal to 1 and all others equal to 0 . If all the components of $\mathbf{x}$ are nonzero, $\mathbf{y}$ can be taken as $\left(-x_2, x_1, 0, \ldots, 0\right)$. This is, of course, not true when $k=1$, since the product of two nonzero real numbers is nonzero.
\end{proof}



\paragraph{Exercise 1.18b} If $k = 1$ and $\mathbf{x} \in R^{k}$, prove that there does not exist $\mathbf{y} \in R^{k}$ such that $\mathbf{y} \neq 0$ but $\mathbf{x} \cdot \mathbf{y}=0$
\begin{proof}
    Not true when $k=1$, since the product of two nonzero real numbers is nonzero.
\end{proof}



\paragraph{Exercise 1.19} Suppose $a, b \in R^k$. Find $c \in R^k$ and $r > 0$ such that $|x-a|=2|x-b|$ if and only if $| x - c | = r$. Prove that $3c = 4b - a$ and $3r = 2 |b - a|$.
\begin{proof}
    Since the solution is given to us, all we have to do is verify it, i.e., we need to show that the equation
$$
|\mathrm{x}-\mathrm{a}|=2|\mathrm{x}-\mathrm{b}|
$$
is equivalent to $|\mathrm{x}-\mathbf{c}|=r$, which says
$$
\left|\mathbf{x}-\frac{4}{3} \mathbf{b}+\frac{1}{3} \mathbf{a}\right|=\frac{2}{3}|\mathbf{b}-\mathbf{a}| .
$$
If we square both sides of both equations, we an equivalent pair of equations, the first of which reduces to
$$
3|\mathbf{x}|^2+2 \mathbf{a} \cdot \mathbf{x}-8 \mathbf{b} \cdot \mathbf{x}-|\mathbf{a}|^2+4|\mathbf{b}|^2=0,
$$
and the second of which reduces to this equation divided by 3 . Hence these equations are indeed equivalent.
\end{proof}



\paragraph{Exercise 2.19a} If $A$ and $B$ are disjoint closed sets in some metric space $X$, prove that they are separated.
\begin{proof}
    We are given that $A \cap B=\varnothing$. Since $A$ and $B$ are closed, this means $A \cap \bar{B}=\varnothing=\bar{A} \cap B$, which says that $A$ and $B$ are separated.
\end{proof}



\paragraph{Exercise 2.24} Let $X$ be a metric space in which every infinite subset has a limit point. Prove that $X$ is separable.
\begin{proof}
    We observe that if the process of constructing $x_j$ did not terminate, the result would be an infinite set of points $x_j, j=1,2, \ldots$, such that $d\left(x_i, x_j\right) \geq \delta$ for $i \neq j$. It would then follow that for any $x \in X$, the open ball $B_{\frac{\delta}{2}}(x)$ contains at most one point of the infinite set, hence that no point could be a limit point of this set, contrary to hypothesis. Hence $X$ is totally bounded, i.e., for each $\delta>0$ there is a finite set $x_1, \ldots, x_{N\delta}$such that $X=\bigcup_{j / 1}^{N\delta} B_\delta\left(x_j\right)$

Let $x_{n_1}, \ldots, x_{n N_n}$ be such that $X=\bigcup_{j / 1}^{N_n} B_{\frac{1}{n}}\left(x_{n j}\right), n=1,2, \ldots$ We claim that $\left\{x_{n j}: 1 \leq j \leq N_n ; n=1,2, \ldots\right\}$ is a countable dense subset of $X$. Indeed
25
if $x \in X$ and $\delta>0$, then $x \in B_{\frac{1}{n}}\left(x_{n j}\right)$ for some $x_{n j}$ for some $n>\frac{1}{\delta}$, and hence $d\left(x, x_{n j}\right)<\delta$. By definition, this means that $\left\{x_{n j}\right\}$ is dense in $X$.
\end{proof}



\paragraph{Exercise 2.25} Prove that every compact metric space $K$ has a countable base.
\begin{proof}
    $K$ can be covered by a finite union of neighborhoods of radius $1 / n$, and this shows that this implies that $K$ is separable.

It is not entirely obvious that a metric space with a countable base is separable. To prove this, let $\left\{V_n\right\}_{n=1}^{\infty}$ be a countable base, and let $x_n \in V_n$. The points $V_n$ must be dense in $X$. For if $G$ is any non-empty open set, then $G$ contains $V_n$ for some $n$, and hence $x_n \in G$. (Thus for a metric space, having a countable base and being separable are equivalent.)
\end{proof}



\paragraph{Exercise 2.27a} Suppose $E\subset\mathbb{R}^k$ is uncountable, and let $P$ be the set of condensation points of $E$. Prove that $P$ is perfect.
\begin{proof}
    We see that $E \cap W$ is at most countable, being a countable union of at-most-countable sets. It remains to show that $P=W^c$, and that $P$ is perfect.
\end{proof}



\paragraph{Exercise 2.27b} Suppose $E\subset\mathbb{R}^k$ is uncountable, and let $P$ be the set of condensation points of $E$. Prove that at most countably many points of $E$ are not in $P$.
\begin{proof}
    If $x \in W^c$, and $O$ is any neighborhood of $x$, then $x \in V_n \subseteq O$ for some n. Since $x \notin W, V_n \cap E$ is uncountable. Hence $O$ contains uncountably many points of $E$, and so $x$ is a condensation point of $E$. Thus $x \in P$, i.e., $W^c \subseteq P$.
Conversely if $x \in W$, then $x \in V_n$ for some $V_n$ such that $V_n \cap E$ is countable. Hence $x$ has a neighborhood (any neighborhood contained in $V_n$ ) containing at most a countable set of points of $E$, and so $x \notin P$, i.e., $W \subseteq P^c$. Hence $P=W^c$.
It is clear that $P$ is closed (since its complement $W$ is open), so that we need only show that $P \subseteq P^{\prime}$. Hence suppose $x \in P$, and $O$ is any neighborhood of $x$. (By definition of $P$ this means $O \cap E$ is uncountable.) We need to show that there is a point $y \in P \cap(O \backslash\{x\})$. If this is not the case, i.e., if every point $y$ in $O \backslash\{x\}$ is in $P^c$, then for each such point $y$ there is a set $V_n$ containing $y$ such that $V_n \cap E$ is at most countable. That would mean that $y \in W$, i.e., that $O \backslash\{x\}$ is contained in $W$. It would follow that $O \cap E \subseteq\{x\} \cup(W \cap E)$, and so $O \cap E$ contains at most a countable set of points, contrary to the hypothesis that $x \in P$. Hence $O$ contains a point of $P$ different from $x$, and so $P \subseteq P^{\prime}$. Thus $P$ is perfect.
\end{proof}



\paragraph{Exercise 2.28} Prove that every closed set in a separable metric space is the union of a (possibly empty) perfect set and a set which is at most countable.
\begin{proof}
    If $E$ is closed, it contains all its limit points, and hence certainly all its condensation points. Thus $E=P \cup(E \backslash P)$, where $P$ is perfect (the set of all condensation points of $E$ ), and $E \backslash P$ is at most countable.

Since a perfect set in a separable metric space has the same cardinality as the real numbers, the set $P$ must be empty if $E$ is countable. The at-mostcountable set $E \backslash P$ cannot be perfect, hence must have isolated points if it is nonempty.
\end{proof}



\paragraph{Exercise 2.29} Prove that every open set in $\mathbb{R}$ is the union of an at most countable collection of disjoint segments.
\begin{proof}
    Let $O$ be open. For each pair of points $x \in O, y \in O$, we define an equivalence relation $x \sim y$ by saying $x \sim y$ if and only if $[\min (x, y), \max (x, y)] \subset$ 0 . This is an equivalence relation, since $x \sim x([x, x] \subset O$ if $x \in O)$; if $x \sim y$, then $y \sim x$ (since $\min (x, y)=\min (y, x)$ and $\max (x, y)=\max (y, x))$; and if $x \sim y$ and $y \sim z$, then $x \sim z([\min (x, z), \max (x, z)] \subseteq[\min (x, y), \max (x, y)] \cup$ $[\min (y, z), \max (y, z)] \subseteq O)$. In fact it is easy to prove that
$$
\min (x, z) \geq \min (\min (x, y), \min (y, z))
$$
and
$$
\max (x, z) \leq \max (\max (x, y), \max (y, z))
$$
It follows that $O$ can be written as a disjoint union of pairwise disjoint equivalence classes. We claim that each equivalence class is an open interval.

To show this, for each $x \in O$; let $A=\{z:[z, x] \subseteq O\}$ and $B=\{z:[x, z] \subseteq$ $O\}$, and let $a=\inf A, b=\sup B$. We claim that $(a, b) \subset O$. Indeed if $a<z<b$, there exists $c \in A$ with $c<z$ and $d \in B$ with $d>z$. Then $z \in[c, x] \cup[x, d] \subseteq O$. We now claim that $(a, b)$ is the equivalence class containing $x$. It is clear that each element of $(a, b)$ is equivalent to $x$ by the way in which $a$ and $b$ were chosen. We need to show that if $z \notin(a, b)$, then $z$ is not equivalent to $x$. Suppose that $z<a$. If $z$ were equivalent to $x$, then $[z, x]$ would be contained in $O$, and so we would have $z \in A$. Hence $a$ would not be a lower bound for $A$. Similarly if $z>b$ and $z \sim x$, then $b$ could not be an upper bound for $B$.

We have now established that $O$ is a union of pairwise disjoint open intervals. Such a union must be at most countable, since each open interval contains a rational number not in any other interval.
\end{proof}



\paragraph{Exercise 3.1a} Prove that convergence of $\left\{s_{n}\right\}$ implies convergence of $\left\{\left|s_{n}\right|\right\}$.
\begin{proof}
    Let $\varepsilon>0$. Since the sequence $\left\{s_n\right\}$ is a Cauchy sequence, there exists $N$ such that $\left|s_m-s_n\right|<\varepsilon$ for all $m>N$ and $n>N$. We then have $\left| |s_m| - |s_n| \right| \leq\left|s_m-s_n\right|<\varepsilon$ for all $m>N$ and $n>N$. Hence the sequence $\left\{\left|s_n\right|\right\}$ is also a Cauchy sequence, and therefore must converge.
\end{proof}



\paragraph{Exercise 3.2a} Prove that $\lim_{n \rightarrow \infty}\sqrt{n^2 + n} -n = 1/2$.
\begin{proof}
    Multiplying and dividing by $\sqrt{n^2+n}+n$ yields
$$
\sqrt{n^2+n}-n=\frac{n}{\sqrt{n^2+n}+n}=\frac{1}{\sqrt{1+\frac{1}{n}}+1} .
$$
It follows that the limit is $\frac{1}{2}$.
\end{proof}



\paragraph{Exercise 3.3} If $s_{1}=\sqrt{2}$, and $s_{n+1}=\sqrt{2+\sqrt{s_{n}}} \quad(n=1,2,3, \ldots),$ prove that $\left\{s_{n}\right\}$ converges, and that $s_{n}<2$ for $n=1,2,3, \ldots$.
\begin{proof}
    Since $\sqrt{2}<2$, it is manifest that if $s_n<2$, then $s_{n+1}<\sqrt{2+2}=2$. Hence it follows by induction that $\sqrt{2}<s_n<2$ for all $n$. In view of this fact,it also follows that $\left(s_n-2\right)\left(s_n+1\right)<0$ for all $n>1$, i.e., $s_n>s_n^2-2=s_{n-1}$. Hence the sequence is an increasing sequence that is bounded above (by 2 ) and so converges. Since the limit $s$ satisfies $s^2-s-2=0$, it follows that the limit is 2.
\end{proof}



\paragraph{Exercise 3.5} For any two real sequences $\left\{a_{n}\right\},\left\{b_{n}\right\}$, prove that $\limsup _{n \rightarrow \infty}\left(a_{n}+b_{n}\right) \leq \limsup _{n \rightarrow \infty} a_{n}+\limsup _{n \rightarrow \infty} b_{n},$ provided the sum on the right is not of the form $\infty-\infty$.
\begin{proof}
    Since the case when $\limsup _{n \rightarrow \infty} a_n=+\infty$ and $\limsup _{n \rightarrow \infty} b_n=-\infty$ has been excluded from consideration, we note that the inequality is obvious if $\limsup _{n \rightarrow \infty} a_n=+\infty$. Hence we shall assume that $\left\{a_n\right\}$ is bounded above.

Let $\left\{n_k\right\}$ be a subsequence of the positive integers such that $\lim _{k \rightarrow \infty}\left(a_{n_k}+\right.$ $\left.b_{n_k}\right)=\limsup _{n \rightarrow \infty}\left(a_n+b_n\right)$. Then choose a subsequence of the positive integers $\left\{k_m\right\}$ such that
$$
\lim _{m \rightarrow \infty} a_{n_{k_m}}=\limsup _{k \rightarrow \infty} a_{n_k} .
$$
The subsequence $a_{n_{k_m}}+b_{n_{k_m}}$ still converges to the same limit as $a_{n_k}+b_{n_k}$, i.e., to $\limsup _{n \rightarrow \infty}\left(a_n+b_n\right)$. Hence, since $a_{n_k}$ is bounded above (so that $\limsup _{k \rightarrow \infty} a_{n_k}$ is finite), it follows that $b_{n_{k_m}}$ converges to the difference
$$
\lim _{m \rightarrow \infty} b_{n_{k_m}}=\lim _{m \rightarrow \infty}\left(a_{n_{k_m}}+b_{n_{k_m}}\right)-\lim _{m \rightarrow \infty} a_{n_{k_m}} .
$$
Thus we have proved that there exist subsequences $\left\{a_{n_{k_m}}\right\}$ and $\left\{b_{n_{k_m}}\right\}$ which converge to limits $a$ and $b$ respectively such that $a+b=\limsup _{n \rightarrow \infty}\left(a_n+b_n^*\right)$. Since $a$ is the limit of a subsequence of $\left\{a_n\right\}$ and $b$ is the limit of a subsequence of $\left\{b_n\right\}$, it follows that $a \leq \limsup _{n \rightarrow \infty} a_n$ and $b \leq \limsup _{n \rightarrow \infty} b_n$, from which the desired inequality follows.
\end{proof}



\paragraph{Exercise 3.6a} Prove that $\lim_{n \rightarrow \infty} \sum_{i<n} a_i = \infty$, where $a_i = \sqrt{i + 1} -\sqrt{i}$.
\begin{proof}
    (a) Multiplying and dividing $a_n$ by $\sqrt{n+1}+\sqrt{n}$, we find that $a_n=\frac{1}{\sqrt{n+1}+\sqrt{n}}$, which is larger than $\frac{1}{2 \sqrt{n+1}}$. The series $\sum a_n$ therefore diverges by comparison with the $p$ series $\left(p=\frac{1}{2}\right)$.
\end{proof}



\paragraph{Exercise 3.7} Prove that the convergence of $\Sigma a_{n}$ implies the convergence of $\sum \frac{\sqrt{a_{n}}}{n}$ if $a_n\geq 0$.
\begin{proof}
    Since $\left(\sqrt{a_n}-\frac{1}{n}\right)^2 \geq 0$, it follows that
$$
\frac{\sqrt{a_n}}{n} \leq \frac{1}{2}\left(a_n^2+\frac{1}{n^2}\right) .
$$
Now $\Sigma a_n^2$ converges by comparison with $\Sigma a_n$ (since $\Sigma a_n$ converges, we have $a_n<1$ for large $n$, and hence $\left.a_n^2<a_n\right)$. Since $\Sigma \frac{1}{n^2}$ also converges ($p$ series, $p=2$ ), it follows that $\Sigma \frac{\sqrt{a_n}}{n}$ converges.
\end{proof}



\paragraph{Exercise 3.8} If $\Sigma a_{n}$ converges, and if $\left\{b_{n}\right\}$ is monotonic and bounded, prove that $\Sigma a_{n} b_{n}$ converges.
\begin{proof}
    We shall show that the partial sums of this series form a Cauchy sequence, i.e., given $\varepsilon>0$ there exists $N$ such that $\left|\sum_{k=m+1}^n a_k b_k\right|\langle\varepsilon$ if $n\rangle$ $m \geq N$. To do this, let $S_n=\sum_{k=1}^n a_k\left(S_0=0\right)$, so that $a_k=S_k-S_{k-1}$ for $k=1,2, \ldots$ Let $M$ be an uppper bound for both $\left|b_n\right|$ and $\left|S_n\right|$, and let $S=\sum a_n$ and $b=\lim b_n$. Choose $N$ so large that the following three inequalities hold for all $m>N$ and $n>N$ :
$$
\left|b_n S_n-b S\right|<\frac{\varepsilon}{3} ; \quad\left|b_m S_m-b S\right|<\frac{\varepsilon}{3} ; \quad\left|b_m-b_n\right|<\frac{\varepsilon}{3 M} .
$$
Then if $n>m>N$, we have, from the formula for summation by parts,
$$
\sum_{k=m+1}^n a_n b_n=b_n S_n-b_m S_m+\sum_{k=m}^{n-1}\left(b_k-b_{k+1}\right) S_k
$$
Our assumptions yield immediately that $\left|b_n S_n-b_m S_m\right|<\frac{2 \varepsilon}{3}$, and
$$
\left|\sum_{k=m}^{n-1}\left(b_k-b_{k+1}\right) S_k\right| \leq M \sum_{k=m}^{n-1}\left|b_k-b_{k+1}\right| .
$$
Since the sequence $\left\{b_n\right\}$ is monotonic, we have
$$
\sum_{k=m}^{n-1}\left|b_k-b_{k+1}\right|=\left|\sum_{k=m}^{n-1}\left(b_k-b_{k+1}\right)\right|=\left|b_m-b_n\right|<\frac{\varepsilon}{3 M},
$$
from which the desired inequality follows.
\end{proof}



\paragraph{Exercise 3.13} Prove that the Cauchy product of two absolutely convergent series converges absolutely.
\begin{proof}
    Since both the hypothesis and conclusion refer to absolute convergence, we may assume both series consist of nonnegative terms. We let $S_n=\sum_{k=0}^n a_n, T_n=\sum_{k=0}^n b_n$, and $U_n=\sum_{k=0}^n \sum_{l=0}^k a_l b_{k-l}$. We need to show that $U_n$ remains bounded, given that $S_n$ and $T_n$ are bounded. To do this we make the convention that $a_{-1}=T_{-1}=0$, in order to save ourselves from having to separate off the first and last terms when we sum by parts. We then have
$$
\begin{aligned}
U_n &=\sum_{k=0}^n \sum_{l=0}^k a_l b_{k-l} \\
&=\sum_{k=0}^n \sum_{l=0}^k a_l\left(T_{k-l}-T_{k-l-1}\right) \\
&=\sum_{k=0}^n \sum_{j=0}^k a_{k-j}\left(T_j-T_{j-1}\right) \\
&=\sum_{k=0}^n \sum_{j=0}^k\left(a_{k-j}-a_{k-j-1}\right) T_j \\
&=\sum_{j=0}^n \sum_{k=j}^n\left(a_{k-j}-a_{k-j-1}\right) T_j
&=\sum_{j=0}^n a_{n-j} T_j \\
&\leq T \sum_{m=0}^n a_m \\
&=T S_n \\
&\leq S T .
\end{aligned}
$$
Thus $U_n$ is bounded, and hence approaches a finite limit.

\end{proof}



\paragraph{Exercise 3.20} Suppose $\left\{p_{n}\right\}$ is a Cauchy sequence in a metric space $X$, and some sequence $\left\{p_{n l}\right\}$ converges to a point $p \in X$. Prove that the full sequence $\left\{p_{n}\right\}$ converges to $p$.
\begin{proof}
    Let $\varepsilon>0$. Choose $N_1$ so large that $d\left(p_m, p_n\right)<\frac{\varepsilon}{2}$ if $m>N_1$ and $n>N_1$. Then choose $N \geq N_1$ so large that $d\left(p_{n_k}, p\right)<\frac{\varepsilon}{2}$ if $k>N$. Then if $n>N$, we have
$$
d\left(p_n, p\right) \leq d\left(p_n, p_{n_{N+1}}\right)+d\left(p_{n_{N+1}}, p\right)<\varepsilon
$$
For the first term on the right is less than $\frac{\varepsilon}{2}$ since $n>N_1$ and $n_{N+1}>N+1>$ $N_1$. The second term is less than $\frac{\varepsilon}{2}$ by the choice of $N$.
\end{proof}



\paragraph{Exercise 3.21} If $\left\{E_{n}\right\}$ is a sequence of closed nonempty and bounded sets in a complete metric space $X$, if $E_{n} \supset E_{n+1}$, and if $\lim _{n \rightarrow \infty} \operatorname{diam} E_{n}=0,$ then $\bigcap_{1}^{\infty} E_{n}$ consists of exactly one point.
\begin{proof}
    Choose $x_n \in E_n$. (We use the axiom of choice here.) The sequence $\left\{x_n\right\}$ is a Cauchy sequence, since the diameter of $E_n$ tends to zero as $n$ tends to infinity and $E_n$ contains $E_{n+1}$. Since the metric space $X$ is complete, the sequence $x_n$ converges to a point $x$, which must belong to $E_n$ for all $n$, since $E_n$ is closed and contains $x_m$ for all $m \geq n$. There cannot be a second point $y$ in all of the $E_n$, since for any point $y \neq x$ the diameter of $E_n$ is less $\operatorname{than} d(x, y)$ for large $n$.
\end{proof}



\paragraph{Exercise 3.22} Suppose $X$ is a nonempty complete metric space, and $\left\{G_{n}\right\}$ is a sequence of dense open sets of $X$. Prove Baire's theorem, namely, that $\bigcap_{1}^{\infty} G_{n}$ is not empty.
\begin{proof}
    Let $F_n$ be the complement of $G_n$, so that $F_n$ is closed and contains no open sets. We shall prove that any nonempty open set $U$ contains a point not in any $F_n$, hence in all $G_n$. To this end, we note that $U$ is not contained in $F_1$, so that there is a point $x_1 \in U \backslash F_1$. Since $U \backslash F_1$ is open, there exists $r_1>0$ such that $B_1$, defined as the open ball of radius $r_1$ about $x_1$, is contained in $U \backslash F_1$. Let $E_1$ be the open ball of radius $\frac{r_1}{2}$ about $x_1$, so that the closure of $E_1$ is contained in $B_1$. Now $F_2$ does not contain $E_1$, and so we can find a point $x_2 \in E_1 \backslash F_2$. Since $E_1 \backslash F_2$ is an open set, there exists a positive number $r_2$ such that $B_2$, the open ball of radius $R_2$ about $x_2$, is contained in $E_1 \backslash F_2$, which in turn is contained in $U \backslash\left(F_1 \cup F_2\right)$. We let $E_2$ be the open ball of radius $\frac{r_2}{2}$ about $x_2$, so that $\bar{E}_2 \subseteq B_2$. Proceeding in this way, we construct a sequence of open balls $E_j$, such that $E_j \supseteq \bar{E}_{j+1}$, and the diameter of $E_j$ tends to zero. By the previous exercise, there is a point $x$ belonging to all the sets $\bar{E}_j$, hence to all the sets $U \backslash\left(F_1 \cup F_2 \cup \cdots \cup F_n\right)$. Thus the point $x$ belongs to $U \cap\left(\cap_1^{\infty} G_n\right)$.
\end{proof}



\paragraph{Exercise 4.1a} Suppose $f$ is a real function defined on $\mathbb{R}$ which satisfies $\lim_{h \rightarrow 0} f(x + h) - f(x - h) = 0$ for every $x \in \mathbb{R}$. Show that $f$ does not need to be continuous.
\begin{proof}
    $$
f(x)= \begin{cases}1 & \text { if } x \text { is an integer } \\ 0 & \text { if } x \text { is not an integer. }\end{cases}
$$
(If $x$ is an integer, then $f(x+h)-f(x-h) \equiv 0$ for all $h$; while if $x$ is not an integer, $f(x+h)-f(x-h)=0$ for $|h|<\min (x-[x], 1+[x]-x)$.
\end{proof}



\paragraph{Exercise 4.2a} If $f$ is a continuous mapping of a metric space $X$ into a metric space $Y$, prove that $f(\overline{E}) \subset \overline{f(E)}$ for every set $E \subset X$. ($\overline{E}$ denotes the closure of $E$).
\begin{proof}
    Let $x \in \bar{E}$. We need to show that $f(x) \in \overline{f(E)}$. To this end, let $O$ be any neighborhood of $f(x)$. Since $f$ is continuous, $f^{-1}(O)$ contains (is) a neighborhood of $x$. Since $x \in \bar{E}$, there is a point $u$ of $E$ in $f^{-1}(O)$. Hence $\frac{f(u)}{f(E)} \in O \cap f(E)$. Since $O$ was any neighborhood of $f(x)$, it follows that $f(x) \in \overline{f(E)}$
\end{proof}



\paragraph{Exercise 4.3} Let $f$ be a continuous real function on a metric space $X$. Let $Z(f)$ (the zero set of $f$ ) be the set of all $p \in X$ at which $f(p)=0$. Prove that $Z(f)$ is closed.
\begin{proof}
    $Z(f)=f^{-1}(\{0\})$, which is the inverse image of a closed set. Hence $Z(f)$ is closed.
\end{proof}



\paragraph{Exercise 4.4a} Let $f$ and $g$ be continuous mappings of a metric space $X$ into a metric space $Y$, and let $E$ be a dense subset of $X$. Prove that $f(E)$ is dense in $f(X)$.
\begin{proof}
    To prove that $f(E)$ is dense in $f(X)$, simply use that $f(X)=f(\bar{E}) \subseteq \overline{f(E)}$.
\end{proof}



\paragraph{Exercise 4.4b} Let $f$ and $g$ be continuous mappings of a metric space $X$ into a metric space $Y$, and let $E$ be a dense subset of $X$. Prove that if $g(p) = f(p)$ for all $p \in E$ then $g(p) = f(p)$ for all $p \in X$.
\begin{proof}
    The function $\varphi: X \rightarrow R^1$ given by
$$
\varphi(p)=d_Y(f(p), g(p))
$$
is continuous, since
$$
\left|d_Y(f(p), g(p))-d_Y(f(q), g(q))\right| \leq d_Y(f(p), f(q))+d_Y(g(p), g(q))
$$
(This inequality follows from the triangle inequality, since
$$
d_Y(f(p), g(p)) \leq d_Y(f(p), f(q))+d_Y(f(q), g(q))+d_Y(g(q), g(p)),
$$
and the same inequality holds with $p$ and $q$ interchanged. The absolute value $\left|d_Y(f(p), g(p))-d_Y(f(q), g(q))\right|$ must be either $d_Y(f(p), g(p))-d_Y(f(q), g(q))$ or $d_Y(f(q), g(q))-d_Y(f(p), g(p))$, and the triangle inequality shows that both of these numbers are at most $d_Y(f(p), f(q))+d_Y(g(p), g(q))$.)
By the previous problem, the zero set of $\varphi$ is closed. But by definition
$$
Z(\varphi)=\{p: f(p)=g(p)\} .
$$
Hence the set of $p$ for which $f(p)=g(p)$ is closed. Since by hypothesis it is dense, it must be $X$.
\end{proof}



\paragraph{Exercise 4.5a} If $f$ is a real continuous function defined on a closed set $E \subset \mathbb{R}$, prove that there exist continuous real functions $g$ on $\mathbb{R}$ such that $g(x)=f(x)$ for all $x \in E$.
\begin{proof}
Following the hint, let the complement of $E$ consist of a countable collection of finite open intervals $\left(a_k, b_k\right)$ together with possibly one or both of the the semi-infinite intervals $(b,+\infty)$ and $(-\infty, a)$. The function $f(x)$ is already defined at $a_k$ and $b_k$, as well as at $a$ and $b$ (if these last two points exist). Define $g(x)$ to be $f(b)$ for $x>b$ and $f(a)$ for $x<a$ if $a$ and $b$ exist. On the interval $\left(a_k, b_k\right)$ let
$$
g(x)=f\left(a_k\right)+\frac{x-a_k}{b_k-a_k}\left(f\left(b_k\right)-f\left(a_k\right)\right) .
$$
Of course we let $g(x)=f(x)$ for $x \in E$. It is now fairly clear that $g(x)$ is continuous. A rigorous proof proceeds as follows. Let $\varepsilon>0$. To choose $\delta>0$ such that $|x-u|<\delta$ implies $|g(x)-g(u)|<\varepsilon$, we consider three cases.
i. If $x>b$, let $\delta=x-b$. Then if $|x-u|<\delta$, it follows that $u>b$ also, so that $g(u)=f(b)=g(x)$, and $|g(u)-g(x)|=0<\varepsilon$. Similarly if $x<a$, let $\delta=a-x$
ii. If $a_k<x<b_k$ and $f\left(a_k\right)=f\left(b_k\right)$, let $\delta=\min \left(x-a_k, b_k-x\right)$. Since $|x-u|<\delta$ implies $a_k<u<b_k$, so that $g(u)=f\left(a_k\right)=f\left(b_k\right)=g(x)$, we again have $|g(x)-g(u)|=0<\varepsilon$. If $a_k<x<b_k$ and $f\left(a_k\right) \neq f\left(b_k\right)$, let $\delta=\min \left(x-a_k, b_k-x, \frac{\left(b_k-a_k\right) \varepsilon}{\left|f\left(b_k\right)-f\left(a_k\right)\right|}\right)$. Then if $|x-u|<\delta$, we again have $a_k<u<b_k$ and so
$$
|g(x)-g(u)|=\frac{|x-u|}{b_k-a_k}\left|f\left(b_k\right)-f\left(a_k\right)\right|<\varepsilon .
$$
iii. If $x \in E$, let $\delta_1$ be such that $|f(u)-f(x)|<\varepsilon$ if $u \in E$ and $|x-u|<\delta_1$. (Subcase a). If there are points $x_1 \in E \cap\left(x-\delta_1, x\right)$ and $x_2 \in E \cap\left(x, x+\delta_1\right)$, let $\delta=\min \left(x-x_1, x_2-x\right)$. If $|u-x|<\delta$ and $u \in E$, then $|f(u)-f(x)|<\varepsilon$ by definition of $\delta_1$. if $u \notin E$, then, since $x_1, x$, and $x_2$ are all in $E$, it follows that $u \in\left(a_k, b_k\right)$, where $a_k \in E, b_k \in E$, and $\left|a_k-x\right|<\delta$ and $\left|b_k-x\right|<\delta$, so that $\left|f\left(a_k\right)-f(x)\right|<\varepsilon$ and $\left|f\left(b_k\right)-f(x)\right|<\varepsilon$. If $f\left(a_k\right)=f\left(b_k\right)$, then $f(u)=f\left(a_k\right)$ also, and we have $|f(u)-f(x)|<\varepsilon$. If $f\left(a_k\right) \neq f\left(b_k\right)$, then
$$
\begin{aligned}
|f(u)-f(x)| & =\left|f\left(a_k\right)-f(x)+\frac{u-a_k}{b_k-a_k}\left(f\left(b_k\right)-f\left(a_k\right)\right)\right| \\
& =\left|\frac{b_k-u}{b_k-a_k}\left(f\left(a_k\right)-f(x)\right)+\frac{u-a_k}{b_k-a_k}\left(f\left(b_k\right)-f(x)\right)\right| \\
& <\frac{b_k-u}{b_k-a_k} \varepsilon+\frac{u-a_k}{b_k-a_k} \varepsilon \\
& =\varepsilon
\end{aligned}
$$
(Subcase b). Suppose $x_2$ does not exist, i.e., either $x=a_k$ or $x=a_k$ and $b_k>a_k+\delta_1$. Let us consider the second of these cases and show how to get $|f(u)-f(x)|<\varepsilon$ for $x<u<x+\delta$. If $f\left(a_k\right)=f\left(b_k\right)$, let $\delta=\delta_1$. If $u>x$ we have $a_k<u<b_k$ and $f(u)=f\left(a_k\right)=f(x)$. If $f\left(a_k\right) \neq f\left(b_k\right)$, let $\delta=$ $\min \left(\delta_1, \frac{\left(b_k-a_k\right) \varepsilon}{\left|f\left(b_k\right)-f\left(a_k\right)\right|}\right)$. Then, just as in Subcase a, we have $|f(u)-f(x)|<\varepsilon$.
The case when $x=b_k$ for some $k$ and $a_k<x-\delta_1$ is handled in exactly the same way.
\end{proof}




\paragraph{Exercise 4.5b} Show that there exist a set $E \subset \mathbb{R}$ and a real continuous function $f$ defined on $E$, such that there does not exist a continuous real function $g$ on $\mathbb{R}$ such that $g(x)=f(x)$ for all $x \in E$.
\begin{proof}
    Let $E:=(0,1)$, and define $f(x):=1 / x$ for all $x \in E$. If $f$ has a continuous extension $g$ to $\mathbb{R}$, then $g$ is continuous on $[-1,1]$, and therefore bounded by the intermediate value theorem. However, $f$ is not bounded in any neighborhood of $x=0$, so therefore $g$ is not bounded either, a contradiction.
\end{proof}



\paragraph{Exercise 4.6} If $f$ is defined on $E$, the graph of $f$ is the set of points $(x, f(x))$, for $x \in E$. In particular, if $E$ is a set of real numbers, and $f$ is real-valued, the graph of $f$ is a subset of the plane. Suppose $E$ is compact, and prove that $f$ is continuous on $E$ if and only if its graph is compact.
\begin{proof}
    Let $Y$ be the co-domain of the function $f$. We invent a new metric space $E \times Y$ as the set of pairs of points $(x, y), x \in E, y \in Y$, with the metric $\rho\left(\left(x_1, y_1\right),\left(x_2, y_2\right)\right)=d_E\left(x_1, x_2\right)+d_Y\left(y_1, y_2\right)$. The function $\varphi(x)=(x, f(x))$ is then a mapping of $E$ into $E \times Y$.

We claim that the mapping $\varphi$ is continuous if $f$ is continuous. Indeed, let $x \in X$ and $\varepsilon>0$ be given. Choose $\eta>0$ so that $d_Y(f(x), f(u))<\frac{\varepsilon}{2}$ if $d_E(x, y)<\eta$. Then let $\delta=\min \left(\eta, \frac{\varepsilon}{2}\right)$. It is easy to see that $\rho(\varphi(x), \varphi(u))<\varepsilon$ if $d_E(x, u)<\delta$. Conversely if $\varphi$ is continuous, it is obvious from the inequality $\rho(\varphi(x), \varphi(u)) \geq d_Y(f(x), f(u))$ that $f$ is continuous.

From these facts we deduce immediately that the graph of a continuous function $f$ on a compact set $E$ is compact, being the image of $E$ under the continuous mapping $\varphi$. Conversely, if $f$ is not continuous at some point $x$, there is a sequence of points $x_n$ converging to $x$ such that $f\left(x_n\right)$ does not converge to $f(x)$. If no subsequence of $f\left(x_n\right)$ converges, then the sequence $\left\{\left(x_n, f\left(x_n\right)\right\}_{n=1}^{\infty}\right.$ has no convergent subsequence, and so the graph is not compact. If some subsequence of $f\left(x_n\right)$ converges, say $f\left(x_{n_k}\right) \rightarrow z$, but $z \neq f(x)$, then the graph of $f$ fails to contain the limit point $(x, z)$, and hence is not closed. A fortiori it is not compact.
\end{proof}



\paragraph{Exercise 4.8a} Let $f$ be a real uniformly continuous function on the bounded set $E$ in $R^{1}$. Prove that $f$ is bounded on $E$.
\begin{proof}
    Let $a=\inf E$ and $b=\sup E$, and let $\delta>0$ be such that $|f(x)-f(y)|<1$ if $x, y \in E$ and $|x-y|<\delta$. Now choose a positive integer $N$ larger than $(b-a) / \delta$, and consider the $N$ intervals $I_k=\left[a+\frac{k-1}{b-a}, a+\frac{k}{b-a}\right], k=1,2, \ldots, N$. For each $k$ such that $I_k \cap E \neq \varnothing$ let $x_k \in E \cap I_k$. Then let $M=1+\max \left\{\left|f\left(x_k\right)\right|\right\}$. If $x \in E$, we have $\left|x-x_k\right|<\delta$ for some $k$, and hence $|f(x)|<M$.
\end{proof}



\paragraph{Exercise 4.8b} Let $E$ be a bounded set in $R^{1}$. Prove that there exists a real function $f$ such that $f$ is uniformly continuous and is not bounded on $E$.
\begin{proof}
    The function $f(x)=x$ is uniformly continuous on the entire line, but not bounded.
\end{proof}



\paragraph{Exercise 4.11a} Suppose $f$ is a uniformly continuous mapping of a metric space $X$ into a metric space $Y$ and prove that $\left\{f\left(x_{n}\right)\right\}$ is a Cauchy sequence in $Y$ for every Cauchy sequence $\{x_n\}$ in $X$.
\begin{proof}
    Suppose $\left\{x_n\right\}$ is a Cauchy sequence in $X$. Let $\varepsilon>0$ be given. Let $\delta>0$ be such that $d_Y(f(x), f(u))<\varepsilon$ if $d_X(x, u)<\delta$. Then choose $N$ so that $d_X\left(x_n, x_m\right)<\delta$ if $n, m>N$. Obviously $d_Y\left(f\left(x_n\right), f\left(x_m\right)\right)<\varepsilon$ if $m, n>N$, showing that $\left\{f\left(x_n\right)\right\}$ is a Cauchy sequence.
\end{proof}



\paragraph{Exercise 4.12} A uniformly continuous function of a uniformly continuous function is uniformly continuous.
\begin{proof}
    Let $f: X \rightarrow Y$ and $g: Y \rightarrow Z$ be uniformly continuous. Then $g \circ f: X \rightarrow Z$ is uniformly continuous, where $g \circ f(x)=g(f(x))$ for all $x \in X$.
To prove this fact, let $\varepsilon>0$ be given. Then, since $g$ is uniformly continuous, there exists $\eta>0$ such that $d_Z(g(u), g(v))<\varepsilon$ if $d_Y(u, v)<\eta$. Since $f$ is uniformly continuous, there exists $\delta>0$ such that $d_Y(f(x), f(y))<\eta$ if $d_X(x, y)<\delta$

It is then obvious that $d_Z(g(f(x)), g(f(y)))<\varepsilon$ if $d_X(x, y)<\delta$, so that $g \circ f$ is uniformly continuous.
\end{proof}


\paragraph{Exercise 4.15} Prove that every continuous open mapping of $R^{1}$ into $R^{1}$ is monotonic.
\begin{proof}
    Suppose $f$ is continuous and not monotonic, say there exist points $a<b<c$ with $f(a)<f(b)$, and $f(c)<f(b)$. Then the maximum value of $f$ on the closed interval $[a, c]$ is assumed at a point $u$ in the open interval $(a, c)$. If there is also a point $v$ in the open interval $(a, c)$ where $f$ assumes its minimum value on $[a, c]$, then $f(a, c)=[f(v), f(u)]$. If no such point $v$ exists, then $f(a, c)=(d, f(u)]$, where $d=\min (f(a), f(c))$. In either case, the image of $(a, c)$ is not open.
\end{proof}



\paragraph{Exercise 4.19} Suppose $f$ is a real function with domain $R^{1}$ which has the intermediate value property: if $f(a)<c<f(b)$, then $f(x)=c$ for some $x$ between $a$ and $b$. Suppose also, for every rational $r$, that the set of all $x$ with $f(x)=r$ is closed. Prove that $f$ is continuous.
\begin{proof}
    The contradiction is evidently that $x_0$ is a limit point of the set of $t$ such that $f(t)=r$, yet, $x_0$ does not belong to this set. This contradicts the hypothesis that the set is closed.
\end{proof}



\paragraph{Exercise 4.21a} Suppose $K$ and $F$ are disjoint sets in a metric space $X, K$ is compact, $F$ is closed. Prove that there exists $\delta>0$ such that $d(p, q)>\delta$ if $p \in K, q \in F$.
\begin{proof}
Following the hint, we observe that $\rho_F(x)$ must attain its minimum value on $K$, i.e., there is some point $r \in K$ such that
$$
\rho_F(r)=\min _{q \in K} \rho_F(q) .
$$
Since $F$ is closed and $r \notin F$, it follows from Exercise $4.20$ that $\rho_F(r)>0$. Let $\delta$ be any positive number smaller than $\rho_F(r)$. Then for any $p \in F, q \in K$, we have
$$
d(p, q) \geq \rho_F(q) \geq \rho_F(r)>\delta .
$$
This proves the positive assertion.
\end{proof}



\paragraph{Exercise 4.24} Assume that $f$ is a continuous real function defined in $(a, b)$ such that $f\left(\frac{x+y}{2}\right) \leq \frac{f(x)+f(y)}{2}$ for all $x, y \in(a, b)$. Prove that $f$ is convex.
\begin{proof}
    We shall prove that
$$
f(\lambda x+(1-\lambda) y) \leq \lambda f(x)+(1-\lambda) f(y)
$$
for all "dyadic rational" numbers, i.e., all numbers of the form $\lambda=\frac{k}{2^n}$, where $k$ is a nonnegative integer not larger than $2^n$. We do this by induction on $n$. The case $n=0$ is trivial (since $\lambda=0$ or $\lambda=1$ ). In the case $n=1$ we have $\lambda=0$ or $\lambda=1$ or $\lambda=\frac{1}{2}$. The first two cases are again trivial, and the third is precisely the hypothesis of the theorem. Suppose the result is proved for $n \leq r$, and consider $\lambda=\frac{k}{2^{r+1}}$. If $k$ is even, say $k=2 l$, then $\frac{k}{2^{r+1}}=\frac{l}{2^r}$, and we can appeal to the induction hypothesis. Now suppose $k$ is odd. Then $1 \leq k \leq 2^{r+1}-1$, and so the numbers $l=\frac{k-1}{2}$ and $m=\frac{k+1}{2}$ are integers with $0 \leq l<m \leq 2^r$. We can now write
$$
\lambda=\frac{s+t}{2},
$$
where $s=\frac{k-1}{2^{r+1}}=\frac{l}{2^r}$ and $t=\frac{k+1}{2^{r+1}}=\frac{m}{2^r}$. We then have
$$
\lambda x+(1-\lambda) y=\frac{[s x+(1-s) y]+[t x+(1-t) y]}{2}
$$
Hence by the hypothesis of the theorem and the induction hypothesis we have
$$
\begin{aligned}
f(\lambda x+(1-\lambda) y) & \leq \frac{f(s x+(1-s) y)+f(t x+(1-t) y)}{2} \\
& \leq \frac{s f(x)+(1-s) f(y)+t f(x)+(1-t) f(y)}{2} \\
&=\left(\frac{s+t}{2}\right) f(x)+\left(1-\frac{s+t}{2}\right) f(y) \\
&=\lambda f(x)+(1-\lambda) f(y)
\end{aligned}
$$
This completes the induction.
Now for each fixed $x$ and $y$ both sides of the inequality
$$
f(\lambda x+(1-\lambda) y) \leq \lambda f(x)+(1-\lambda) f(y)
$$
are continuous functions of $\lambda$. Hence the set on which this inequality holds (the inverse image of the closed set $[0, \infty)$ under the mapping $\lambda \mapsto \lambda f(x)+(1-$ $\lambda) f(y)-f(\lambda x+(1-\lambda) y))$ is a closed set. Since it contains all the points $\frac{k}{2^n}$, $0 \leq k \leq n, n=1,2, \ldots$, it must contain the closure of this set of points, i.e., it must contain all of $[0,1]$. Thus $f$ is convex.
\end{proof}



\paragraph{Exercise 5.1} Let $f$ be defined for all real $x$, and suppose that $|f(x)-f(y)| \leq (x-y)^{2}$ for all real $x$ and $y$. Prove that $f$ is constant.
\begin{proof}
    Dividing by $x-y$, and letting $x \rightarrow y$, we find that $f^{\prime}(y)=0$ for all $y$. Hence $f$ is constant.
\end{proof}



\paragraph{Exercise 5.2} Suppose $f^{\prime}(x)>0$ in $(a, b)$. Prove that $f$ is strictly increasing in $(a, b)$, and let $g$ be its inverse function. Prove that $g$ is differentiable, and that $g^{\prime}(f(x))=\frac{1}{f^{\prime}(x)} \quad(a<x<b)$.
\begin{proof}
   For any $c, d$ with $a<c<d<b$ there exists a point $p \in(c, d)$ such that $f(d)-f(c)=f^{\prime}(p)(d-c)>0$. Hence $f(c)<f(d)$

We know from Theorem $4.17$ that the inverse function $g$ is continuous. (Its restriction to each closed subinterval $[c, d]$ is continuous, and that is sufficient.) Now observe that if $f(x)=y$ and $f(x+h)=y+k$, we have
$$
\frac{g(y+k)-g(y)}{k}-\frac{1}{f^{\prime}(x)}=\frac{1}{\frac{f(x+h)-f(x)}{h}}-\frac{1}{f^{\prime}(x)}
$$
Since we know $\lim \frac{1}{\varphi(t)}=\frac{1}{\lim \varphi(t)}$ provided $\lim \varphi(t) \neq 0$, it follows that for any $\varepsilon>0$ there exists $\eta>0$ such that
$$
\left|\frac{1}{\frac{f(x+h)-f(x)}{h}}-\frac{1}{f^{\prime}(x)}\right|<\varepsilon
$$
if $0<|h|<\eta$. Since $h=g(y+k)-g(y)$, there exists $\delta>0$ such that $0<|h|<\eta$ if $0<|k|<\delta$. The proof is now complete. 
\end{proof}



\paragraph{Exercise 5.3} Suppose $g$ is a real function on $R^{1}$, with bounded derivative (say $\left|g^{\prime}\right| \leq M$ ). Fix $\varepsilon>0$, and define $f(x)=x+\varepsilon g(x)$. Prove that $f$ is one-to-one if $\varepsilon$ is small enough.
\begin{proof}
    If $0<\varepsilon<\frac{1}{M}$, we certainly have
$$
f^{\prime}(x) \geq 1-\varepsilon M>0,
$$
and this implies that $f(x)$ is one-to-one, by the preceding problem.
\end{proof}



\paragraph{Exercise 5.4} If $C_{0}+\frac{C_{1}}{2}+\cdots+\frac{C_{n-1}}{n}+\frac{C_{n}}{n+1}=0,$ where $C_{0}, \ldots, C_{n}$ are real constants, prove that the equation $C_{0}+C_{1} x+\cdots+C_{n-1} x^{n-1}+C_{n} x^{n}=0$ has at least one real root between 0 and 1.
\begin{proof}
    Consider the polynomial
$$
p(x)=C_0 x+\frac{C_1}{2} x^2+\cdots+\frac{C_{n-1}}{n} x^n+\frac{C_n}{n+1} x^{n+1},
$$
whose derivative is
$$
p^{\prime}(x)=C_0+C_1 x+\cdots+C_{n-1} x^{n-1}+C_n x^n .
$$
It is obvious that $p(0)=0$, and the hypothesis of the problem is that $p(1)=0$. Hence Rolle's theorem implies that $p^{\prime}(x)=0$ for some $x$ between 0 and 1 .
\end{proof}



\paragraph{Exercise 5.5} Suppose $f$ is defined and differentiable for every $x>0$, and $f^{\prime}(x) \rightarrow 0$ as $x \rightarrow+\infty$. Put $g(x)=f(x+1)-f(x)$. Prove that $g(x) \rightarrow 0$ as $x \rightarrow+\infty$.
\begin{proof}
    Let $\varepsilon>0$. Choose $x_0$ such that $\left|f^{\prime}(x)\right|<\varepsilon$ if $x>x_0$. Then for any $x \geq x_0$ there exists $x_1 \in(x, x+1)$ such that
$$
f(x+1)-f(x)=f^{\prime}\left(x_1\right) .
$$
Since $\left|f^{\prime}\left(x_1\right)\right|<\varepsilon$, it follows that $|f(x+1)-f(x)|<\varepsilon$, as required.
\end{proof}



\paragraph{Exercise 5.6} Suppose (a) $f$ is continuous for $x \geq 0$, (b) $f^{\prime}(x)$ exists for $x>0$, (c) $f(0)=0$, (d) $f^{\prime}$ is monotonically increasing. Put $g(x)=\frac{f(x)}{x} \quad(x>0)$ and prove that $g$ is monotonically increasing.
\begin{proof}
    Put
$$
g(x)=\frac{f(x)}{x} \quad(x>0)
$$
and prove that $g$ is monotonically increasing.
By the mean-value theorem
$$
f(x)=f(x)-f(0)=f^{\prime}(c) x
$$
for some $c \in(0, x)$. Since $f^{\prime}$ is monotonically increasing, this result implies that $f(x)<x f^{\prime}(x)$. It therefore follows that
$$
g^{\prime}(x)=\frac{x f^{\prime}(x)-f(x)}{x^2}>0,
$$
so that $g$ is also monotonically increasing.
\end{proof}



\paragraph{Exercise 5.7} Suppose $f^{\prime}(x), g^{\prime}(x)$ exist, $g^{\prime}(x) \neq 0$, and $f(x)=g(x)=0$. Prove that $\lim _{t \rightarrow x} \frac{f(t)}{g(t)}=\frac{f^{\prime}(x)}{g^{\prime}(x)}.$
\begin{proof}
    Since $f(x)=g(x)=0$, we have
$$
\begin{aligned}
\lim _{t \rightarrow x} \frac{f(t)}{g(t)} &=\lim _{t \rightarrow x} \frac{\frac{f(t)-f(x)}{t-x}}{\frac{g(t)-g(x)}{t-x}} \\
&=\frac{\lim _{t \rightarrow x} \frac{f(t)-f(x)}{t-x}}{\lim _{t \rightarrow x} \frac{g(t)-g(x)}{t-x}} \\
&=\frac{f^{\prime}(x)}{g^{\prime}(x)}
\end{aligned}
$$
\end{proof}



\paragraph{Exercise 5.15} Suppose $a \in R^{1}, f$ is a twice-differentiable real function on $(a, \infty)$, and $M_{0}, M_{1}, M_{2}$ are the least upper bounds of $|f(x)|,\left|f^{\prime}(x)\right|,\left|f^{\prime \prime}(x)\right|$, respectively, on $(a, \infty)$. Prove that $M_{1}^{2} \leq 4 M_{0} M_{2} .$
\begin{proof}
    The inequality is obvious if $M_0=+\infty$ or $M_2=+\infty$, so we shall assume that $M_0$ and $M_2$ are both finite. We need to show that
$$
\left|f^{\prime}(x)\right| \leq 2 \sqrt{M_0 M_2}
$$
for all $x>a$. We note that this is obvious if $M_2=0$, since in that case $f^{\prime}(x)$ is constant, $f(x)$ is a linear function, and the only bounded linear function is a constant, whose derivative is zero. Hence we shall assume from now on that $0<M_2<+\infty$ and $0<M_0<+\infty$.
Following the hint, we need only choose $h=\sqrt{\frac{M_0}{M_2}}$, and we obtain
$$
\left|f^{\prime}(x)\right| \leq 2 \sqrt{M_0 M_2},
$$
which is precisely the desired inequality.
The case of equality follows, since the example proposed satisfies
$$
f(x)=1-\frac{2}{x^2+1}
$$
for $x \geq 0$. We see easily that $|f(x)| \leq 1$ for all $x>-1$. Now $f^{\prime}(x)=\frac{4 x}{\left(x^2+1\right)^2}$ for $x>0$ and $f^{\prime}(x)=4 x$ for $x<0$. It thus follows from Exercise 9 above that $f^{\prime}(0)=0$, and that $f^{\prime}(x)$ is continuous. Likewise $f^{\prime \prime}(x)=4$ for $x<0$ and $f^{\prime \prime}(x)=\frac{4-4 x^2}{\left(x^2+1\right)^3}=-4 \frac{x^2-1}{\left(x^2+1\right)^3}$. This shows that $\left|f^{\prime \prime}(x)\right|<4$ for $x>0$ and also that $\lim _{x \rightarrow 0} f^{\prime \prime}(x)=4$. Hence Exercise 9 again implies that $f^{\prime \prime}(x)$ is continuous and $f^{\prime \prime}(0)=4$.

On $n$-dimensional space let $\mathbf{f}(x)=\left(f_1(x), \ldots, f_n(x)\right), M_0=\sup |\mathbf{f}(x)|$, $M_1=\sup \left|\mathbf{f}^{\prime}(x)\right|$, and $M_2=\sup \left|\mathbf{f}^{\prime \prime}(x)\right|$. Just as in the numerical case, there is nothing to prove if $M_2=0$ or $M_0=+\infty$ or $M_2=+\infty$, and so we assume $0<M_0<+\infty$ and $0<M_2<\infty$. Let $a$ be any positive number less than $M_1$, let $x_0$ be such that $\left|\mathbf{f}^{\prime}\left(x_0\right)\right|>a$, and let $\mathbf{u}=\frac{1}{\left|\mathbf{f}^{\prime}\left(x_0\right)\right|} \mathbf{f}^{\prime}\left(x_0\right)$. Consider the real-valued function $\varphi(x)=\mathrm{u} \cdot \mathrm{f}(x)$. Let $N_0, N_1$, and $N_2$ be the suprema of $|\varphi(x)|,\left|\varphi^{\prime}(x)\right|$, and $\left|\varphi^{\prime \prime}(x)\right|$ respectively. By the Schwarz inequality we have (since $|\mathbf{u}|=1) N_0 \leq M_0$ and $N_2 \leq M_2$, while $N_1 \geq \varphi\left(x_0\right)=\left|\mathbf{f}^{\prime}\left(x_0\right)\right|>a$. We therefore have $a^2<4 N_0 N_2 \leq 4 M_0 M_2$. Since $a$ was any positive number less than $M_1$, we have $M_1^2 \leq 4 M_0 M_2$, i.e., the result holds also for vector-valued functions.

Equality can hold on any $R^n$, as we see by taking $\mathbf{f}(x)=(f(x), 0, \ldots, 0)$ or $\mathbf{f}(x)=(f(x), f(x), \ldots, f(x))$, where $f(x)$ is a real-valued function for which equality holds.

\end{proof}



\paragraph{Exercise 5.17} Suppose $f$ is a real, three times differentiable function on $[-1,1]$, such that $f(-1)=0, \quad f(0)=0, \quad f(1)=1, \quad f^{\prime}(0)=0 .$ Prove that $f^{(3)}(x) \geq 3$ for some $x \in(-1,1)$.
\begin{proof}
    Following the hint, we observe that Theorem $5.15$ (Taylor's formula with remainder) implies that
$$
\begin{aligned}
f(1) &=f(0)+f^{\prime}(0)+\frac{1}{2} f^{\prime \prime}(0)+\frac{1}{6} f^{(3)}(s) \\
f(-1) &=f(0)-f^{\prime}(0)+\frac{1}{2} f^{\prime \prime}(0)-\frac{1}{6} f^{(3)}(t)
\end{aligned}
$$
for some $s \in(0,1), t \in(-1,0)$. By subtracting the second equation from the first and using the given values of $f(1), f(-1)$, and $f^{\prime}(0)$, we obtain
$$
1=\frac{1}{6}\left(f^{(3)}(s)+f^{(3)}(t)\right),
$$
which is the desired result. Note that we made no use of the hypothesis $f(0)=0$.
\end{proof}



\end{document}
